---
title: "Module 8 Probability and Distributions"
author: "Zach C"
date: "October 14, 2017"
output: html_document
---
>Random Variable = variable whose outcomes are assumed to arise by chance or according to some random or stochastic mechanism. 

Discrete Random Variables are random variables that can assume only a countable number of discrete possibilities

Continuous Random Variables are random variables that can assume any real number value within a given range 

>A probability function is a mathematical function that describes the chance associated with a random variable having a particular outcome or falling within a given range of outcome values

Probability Mass Functions (PMFs) are associated with discrete random variables. These functions describe the probability that a random variable takes a particular discrete value.

>Rolling a die
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#1 How to roll a die
library(manipulate)
outcomes <- c(1, 2, 3, 4, 5, 6)
manipulate(hist(sample(outcomes, n, replace = TRUE), breaks = c(0.5, 1.5, 2.5, 
    3.5, 4.5, 5.5, 6.5), probability = TRUE, main = paste("Histogram of Outcomes of ", 
    n, " Die Rolls", sep = ""), xlab = "roll", ylab = "probability"), n = slider(0, 
    10000, initial = 100, step = 100))


#2 Roll a 2 dice 1000 times
nrolls <- 1000
roll <- function(x) {
    sample(1:6, x, replace = TRUE)
}
two_dice <- roll(nrolls) + roll(nrolls)
hist(two_dice, breaks = c(1.5:12.5), probability = TRUE, main = "Rolling Two Dice", 
    xlab = "sum of rolls", ylab = "probability")


```

>Intro to Random Variables
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#1 Flip Coin

outcomes <- c("heads", "tails")
prob <- c(1/2, 1/2)
barplot(prob, ylim = c(0, 0.6), names.arg = outcomes, space = 0.1, xlab = "outcome", 
    ylab = "Pr(X = outcome)", main = "Probability Mass Function")

cumprob <- cumsum(prob)
barplot(cumprob, names.arg = outcomes, space = 0.1, xlab = "outcome", ylab = "Cumulative Pr(X)", 
    main = "Cumulative Probability")

#2 ROll a die
outcomes <- c(1, 2, 3, 4, 5, 6)
prob <- c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)
barplot(prob, ylim = c(0, 0.5), names.arg = outcomes, space = 0.1, xlab = "outcome", 
    ylab = "Pr(X = outcome)", main = "Probability Mass Function")

cumprob <- cumsum(prob)
barplot(cumprob, names.arg = outcomes, space = 0.1, xlab = "outcome", ylab = "Cumulative Pr(X)", 
    main = "Cumulative Probability")
```

>Probability Density Functions (PDFs) are associated with continuous random variables. These functions describe the probability that a random variable falls within a given range of outcome values. The probability associated with that range equals the area under the density function for that range.

F(x) ??? 0 for all ?????? ??? x ??? +??? and the total area under the function f(x) = 1

>Beta distribution = a family of continuous probability distributions defined over the interval [0, 1] and parametrized by two positive shape parameters, denoted by ?? and ??

f(x) = K[x^(?????1)][(1???x)^?????1]
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
a <- 2
b <- 1
K <- 2
x <- seq(from = 0, to = 1, by = 0.025)
fx <- K * x^(a - 1) * (1 - x)^(b - 1)
lower_x <- seq(from = -0.25, to = 0, by = 0.025)  # add some values of x less than zero
upper_x <- seq(from = 1, to = 1.25, by = 0.025)  # add some values of x greater than one
lower_fx <- rep(0, 11)  # add fx=0 values to x<0
upper_fx <- rep(0, 11)  # add fx=0 values to x>1
x <- c(lower_x, x, upper_x)  # paste xs together
fx <- c(lower_fx, fx, upper_fx)  # paste fxs together
d <- as.data.frame(cbind(x, fx))
p <- ggplot(data = d, aes(x = x, y = fx)) + xlab("x") + ylab("f(x)") + geom_line()

```

Cumulative distribution function, or CDF, of a random variable is defined as the probability of observing a random variable X taking the value of x or less
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
x <- seq(from = 0, to = 1, by = 0.005)
prob <- 0.5 * x * K * x^(a - 1) * (1 - x)^(b - 1)
barplot(prob, names.arg = x, space = 0, main = "Cumulative Probability", xlab = "x", 
    ylab = "Pr(X ??? x)")

#The built in R function for the Beta Distribution, pbeta(), can give us the cumulative probability directly, if we specify the values of ?? = 2 and ??= 1.The other related Beta Distribution functions, e.g., rbeta(), dbeta(), and qbeta(), are also useful. rbeta() draws random observations from a specfied beta distribution. dbeta() gives the point estimate of the beta density function at the value of the argument x, and qbeta() is essentially the converse of pbeta(), i.e., it tells you the value of x that is associated with a particular cumulative probability, or quantile, of the cumulative distribution function.

pbeta(0.75, 2, 1)  # cumulative probability for x ??? 0.75

pbeta(0.7, 2, 1)  # yields .49

qbeta(0.49, 2, 1)  # yield 0.7
```


>Expected Mean and Variance of Random Variables

??_X = Expectation for X = ??? (x_i)[Pr(X=x_i)] for all x from x_i to x_k

(??^2)_X = Variance of X = ??? (x_i?????_X)^2[Pr(X=x_i) for all x from x_i to x_k
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#X = (1 * 1/6) + (2 * 1/6) + . + (6 * 1/6) = 3.5
m <- sum(seq(1:6) * 1/6)
#[1] 3.5

#the expected variance
#[(1 - 3.5)^2 * (1/6)] + [(2 - 3.5)^2 * (1/6)] + . + [(6 - 3.5)^2 * (1/6)] =
var <- sum((seq(1:6) - mean(seq(1:6)))^2 * (1/6))
#[1] 2.916667
```

>The Bernoulli Distribution is the probability distribution of a binary random variable, i.e., a variable that has only two possible outcomes.

PMF = f(x)= (p^x)[(1???p)^(1???x)] where x= {0 or 1}

For this distribution, ??X= p and (??^2)_X = p(1???p)

>The Bernoulli distribution is a special case of the Binomial Distribution. The binomial distribution is typically used to model the probability of a number of "successes" k out of a set of "trials" n, i.e., for counts of a particular outcome.

PMF=f(x)= (n-choose-k, nck)(p^k)[(1-p)^n-k]

(nck)=n!/[k!(n-k)!]

For this, ??X = np and (??^2_X) = np(1-p).
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#1 What is the chance of getting a "1" on each of six or three  consecutive rolls of a die? 
n <- 6  # number of trials
k <- 6  # number of successes
p <- 1/6
prob <- (factorial(n)/(factorial(k) * factorial(n - k))) * (p^k) * (1 - p)^(n - 
    k)
prob

#[1] 2.143347e-05

k <- 3  # number of successes
prob <- (factorial(n)/(factorial(k) * factorial(n - k))) * (p^k) * (1 - p)^(n - 
    k)
prob

#[1] 0.05358368

#R function 
dbinom(x = k, size = n, prob = p)

#[1] 0.05358368

#2 What is the expected number of "1"s to occur in six consecutive rolls?
probset <- dbinom(x = 0:6, size = 6, prob = 1/6)  # x is number of successes, size is number of trials
barplot(probset, names.arg = 0:6, space = 0, xlab = "outcome", ylab = "Pr(X = outcome)", 
    main = "Probability Mass Function")

cumprob = cumsum(probset)
barplot(cumprob, names.arg = 0:6, space = 0.1, xlab = "outcome", ylab = "Cumulative Pr(X)", 
    main = "Cumulative Probability")

#3 The probability of observing more than 3 rolls of "1" is given as.

1 - pnbinom(q = 3, size = 6, prob = 1/6)
# [1] 0.9988642

#4 The probability of observing 3 or more rolls of "1" is.

1 - pbinom(q = 2, size = 6, prob = 1/6)  # note here that the q argument is '2'
# [1] 0.06228567
```

>The Poisson Distribution is often used to model open ended counts of independently occuring events

PMF = f(x) = {[(??^x)exp(-??)]}/(x!) where mean expectation and variance = ??
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
x <- 0:10
l = 3.5
probset <- dpois(x = x, lambda = l)
barplot(probset, names.arg = x, space = 0, xlab = "x", ylab = "Pr(X = x)", main = "Probability Mass Function")

x <- 0:10
l <- 3.5
barplot(ppois(q = x, lambda = l), ylim = 0:1, space = 0, names.arg = x, xlab = "x", 
    ylab = "Pr(X ??? x)", main = "Cumulative Probability")
```

>Uniform Distribution is the simplest probability density function describing a continuous random variable. The probability is uniform and does not fluctuate across the range of x values in a given interval.

f(x)= 1/(b-a) where a ??? x ??? b and 0 for x < a and x > b

mean = (a+b)/2, variance = [(b-a)^2]/12
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
a <- 4
b <- 8
x <- seq(from = a - (b - a), to = b + (b - a), by = 0.01)
fx <- dunif(x, min = a, max = b)  # dunif() evaluates the density at each x
plot(x, fx, type = "l", xlab = "x", ylab = "f(x)", main = "Probability Density Function")

plot(x, punif(q = x, min = a, max = b), type = "l", xlab = "x", ylab = "Pr(X ??? x)", 
    main = "Cumulative Probability")  # punif() is the cumulative probability density up to a given x
```

>Gaussian Distribution 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
mu <- 4
sigma <- 1.5
curve(dnorm(x, mu, sigma), mu - 4 * sigma, mu + 4 * sigma, main = "Normal Curve", 
    xlab = "x", ylab = "f(x)")

#You can also use pnorm() to calculate the probability of an observation drawn from the population falling within a particular interval. For example, for a normally distributed population variable with ?? = 6 and ??= 2, the probability of a random observation falling between 7 and 8 is:

p <- pnorm(8, mean = 6, sd = 2) - pnorm(7, mean = 6, sd = 2)
# [1] 0.1498823

#Create a vector, v, containing n random numbers selected from a normal distribution with mean ?? and standard deviation ??.
n <- 1000
mu <- 3.5
sigma <- 4
v <- rnorm(n, mu, sigma)
hist(v, breaks = seq(from = -15, to = 20, by = 0.5), probability = TRUE)
```

>A quantile-quantile or "Q-Q" plot can be used to look at whether a set of data seem to follow a normal distribution. A Q-Q plot is a graphical method for generally comparing two probability distributions. To examine a set of data for normality graphically, you plot the quantiles for your actual data (as the y values) versus the theoretical quantiles (as the x values) pulled from a normal distribution. If the two distributions being compared are similar, the points in the plot will approximately lie on the line y = x.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
qqnorm(v, main = "Normal QQ plot random normal variables")
qqline(v, col = "gray")
```

>Standard Normal Distribution = Any normal distribution with mean ?? and standard deviation ?? can be converted into what is called the standard normal distribution, where the mean is zero and the standard deviation is 1.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
x <- rnorm(10000, mean = 5, sd = 8)  # simulate from a normal distribution with mean 5 and SD 8
hist(x)
mean(x)  # really close to 5
# [1] 4.968016
sd(x)  # really close to 8
# [1] 7.994792

z <- (x - mean(x))/sd(x)  # standardized!
hist(z)
mean(z)  # really close to zero
# [1] -2.504751e-18
sd(z)  
# [1] 1


#Example of sampling from a population: a population of 1 million zombies whose age at zombification is characterized by a normal distribution with a mean of 25 years and a standard deviation of 5 years

set.seed(1)
x <- rnorm(1e+06, 25, 5)
hist(x, probability = TRUE)

#now sample the zombie population by trapping sets of zombies and determining the mean age in each set. We sample without replacement from the original population for each set. Let's do that 100 times with samples of size 5 and store these in a list.

k <- 1000  # number of samples
n <- 5  # size of each sample
s <- NULL  # dummy variable to hold each sample
for (i in 1:k) {
    s[[i]] <- sample(x, size = n, replace = FALSE)
}

m <- NULL
for (i in 1:k) {
    m[i] <- mean(s[[i]])
}
mean(m)  
# [1] 24.95602

mu <- mean(x)
mu
# [1] 25.00023



